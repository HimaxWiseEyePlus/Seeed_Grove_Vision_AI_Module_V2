./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/op_macros.h:24:13:void AbortImpl()	8	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/div.cc:68:7:void* tflite::{anonymous}::Init(TfLiteContext*, const char*, size_t)	8	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/div.cc:73:14:TfLiteStatus tflite::{anonymous}::Prepare(TfLiteContext*, TfLiteNode*)	48	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/reference/process_broadcast_shapes.h:40:13:bool tflite::reference_ops::ProcessBroadcastShapes(const tflite::RuntimeShape&, const tflite::RuntimeShape&, tflite::ArithmeticParams*)	80	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/div.cc:204:20:TfLiteRegistration tflite::Register_DIV()	16	static
./library/inference/tflmtag2209_u55tag2205/third_party/gemmlowp/fixedpoint/fixedpoint.h:842:25:gemmlowp::FixedPoint<tRawType, 0> gemmlowp::one_over_one_plus_x_for_x_in_0_1(FixedPoint<tRawType, 0>) [with tRawType = long int]	20	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/reference/div.h:45:13:void tflite::reference_ops::DivElementwise(int, const tflite::ArithmeticParams&, const T*, const T*, T*) [with T = signed char]	40	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:961:13:void tflite::NdArrayDescsForElementwiseBroadcast(const RuntimeShape&, const RuntimeShape&, NdArrayDesc<N>*, NdArrayDesc<N>*) [with int N = 5]	72	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:1057:51:typename std::enable_if<(DIM != (N - 1)), void>::type tflite::NDOpsHelperImpl(const NdArrayDesc<N>&, const Calc&, int*) [with int N = 5; int DIM = 0; Calc = reference_ops::BroadcastDivSlowQuantized<signed char, 5>(const tflite::ArithmeticParams&, const tflite::RuntimeShape&, const signed char*, const tflite::RuntimeShape&, const signed char*, const tflite::RuntimeShape&, signed char*)::<lambda(int*)>]	64	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/div.cc:130:14:TfLiteStatus tflite::{anonymous}::EvalQuantized(TfLiteContext*, TfLiteNode*, TfLiteDivParams*, const OpDataDiv*, const TfLiteEvalTensor*, const TfLiteEvalTensor*, TfLiteEvalTensor*)	480	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:1057:51:typename std::enable_if<(DIM != (N - 1)), void>::type tflite::NDOpsHelperImpl(const NdArrayDesc<N>&, const Calc&, int*) [with int N = 5; int DIM = 3; Calc = reference_ops::BroadcastDivSlow<float>(const tflite::ArithmeticParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)::<lambda(int*)>]	64	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/div.cc:100:6:void tflite::{anonymous}::EvalDiv(TfLiteContext*, TfLiteNode*, TfLiteDivParams*, const OpDataDiv*, const TfLiteEvalTensor*, const TfLiteEvalTensor*, TfLiteEvalTensor*)	504	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/div.cc:173:14:TfLiteStatus tflite::{anonymous}::Eval(TfLiteContext*, TfLiteNode*)	24	static

./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/op_macros.h:24:13:void AbortImpl()	8	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/sub.cc:34:7:void* tflite::SubInit(TfLiteContext*, const char*, size_t)	8	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/reference/process_broadcast_shapes.h:40:13:bool tflite::reference_ops::ProcessBroadcastShapes(const tflite::RuntimeShape&, const tflite::RuntimeShape&, tflite::ArithmeticParams*)	80	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/sub.cc:164:20:TfLiteRegistration tflite::Register_SUB()	16	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:961:13:void tflite::NdArrayDescsForElementwiseBroadcast(const RuntimeShape&, const RuntimeShape&, NdArrayDesc<N>*, NdArrayDesc<N>*) [with int N = 5]	72	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:1057:51:typename std::enable_if<(DIM != (N - 1)), void>::type tflite::NDOpsHelperImpl(const NdArrayDesc<N>&, const Calc&, int*) [with int N = 5; int DIM = 0; Calc = reference_ops::BroadcastQuantSubSlow<short int>(const tflite::ArithmeticParams&, const tflite::RuntimeShape&, const short int*, const tflite::RuntimeShape&, const short int*, const tflite::RuntimeShape&, short int*)::<lambda(int*)>]	88	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:1057:51:typename std::enable_if<(DIM != (N - 1)), void>::type tflite::NDOpsHelperImpl(const NdArrayDesc<N>&, const Calc&, int*) [with int N = 5; int DIM = 1; Calc = reference_ops::BroadcastQuantSubSlow<signed char>(const tflite::ArithmeticParams&, const tflite::RuntimeShape&, const signed char*, const tflite::RuntimeShape&, const signed char*, const tflite::RuntimeShape&, signed char*)::<lambda(int*)>]	56	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/sub.cc:66:14:TfLiteStatus tflite::EvalSubQuantized(TfLiteContext*, TfLiteNode*, TfLiteSubParams*, const OpDataSub*, const TfLiteEvalTensor*, const TfLiteEvalTensor*, TfLiteEvalTensor*)	888	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:1057:51:typename std::enable_if<(DIM != (N - 1)), void>::type tflite::NDOpsHelperImpl(const NdArrayDesc<N>&, const Calc&, int*) [with int N = 5; int DIM = 3; Calc = reference_ops::BroadcastSubSlow<>(const tflite::ArithmeticParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*)::<lambda(int*)>]	56	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/sub.cc:39:6:void tflite::EvalSub(TfLiteContext*, TfLiteNode*, TfLiteSubParams*, const OpDataSub*, const TfLiteEvalTensor*, const TfLiteEvalTensor*, TfLiteEvalTensor*)	480	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/sub.cc:137:14:TfLiteStatus tflite::SubEval(TfLiteContext*, TfLiteNode*)	48	static
